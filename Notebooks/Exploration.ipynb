{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8908f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7b57032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.pinn_model import TrafficFlowForLWR_PINN, TrafficFlowForARZ_PINN\n",
    "from Scripts.physics import lwr_pde_residual, physics_loss_calculator\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25aab8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pd.read_csv('peachtree_dir2_lane1_10m_1s_10min.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12491c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x_data['x_nd'].values, dtype=torch.float32).reshape(-1,1)\n",
    "t = torch.tensor(x_data['t_nd'].values, dtype=torch.float32).reshape(-1,1)\n",
    "rho = torch.tensor(x_data['rho_nd'].values, dtype=torch.float32).reshape(-1,1)\n",
    "u = torch.tensor(x_data['u_nd'].values, dtype=torch.float32).reshape(-1,1)\n",
    "mask = torch.tensor(x_data['mask'].values, dtype=torch.bool).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27dd86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx = mask.squeeze(1)\n",
    "x, t, rho, u = x[valid_idx], t[valid_idx], rho[valid_idx], u[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e7fb874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.220444\n",
      "Epoch 100, Loss: 0.050913\n",
      "Epoch 200, Loss: 0.040310\n",
      "Epoch 300, Loss: 0.037296\n",
      "Epoch 400, Loss: 0.037047\n",
      "Epoch 500, Loss: 0.036931\n",
      "Epoch 600, Loss: 0.036870\n",
      "Epoch 700, Loss: 0.036837\n",
      "Epoch 800, Loss: 0.036816\n",
      "Epoch 900, Loss: 0.036810\n"
     ]
    }
   ],
   "source": [
    "\"\"\" ### LWR Model Approximation using PINNs ###\"\"\"\n",
    "\n",
    "lwr_model = TrafficFlowForLWR_PINN(hidden_layers=8, neurons_per_layer=20)\n",
    "optimizer = torch.optim.Adam(lwr_model.parameters(), lr=0.001)\n",
    "\n",
    "alpha = 1\n",
    "beta = 1\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Data loss on known density values only\n",
    "    data_loss = torch.mean((lwr_model(x, t) - rho)**2)\n",
    "    # Physics loss\n",
    "    physics_loss = torch.mean(lwr_pde_residual(lwr_model, x, t)**2)\n",
    "    total_loss = alpha * data_loss + beta * physics_loss\n",
    "\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "965f7c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 284.028076\n",
      "Epoch 100, Loss: 0.550987\n",
      "Epoch 200, Loss: 0.499754\n",
      "Epoch 300, Loss: 0.476732\n",
      "Epoch 400, Loss: 0.463799\n",
      "Epoch 500, Loss: 0.455871\n",
      "Epoch 600, Loss: 0.450707\n",
      "Epoch 700, Loss: 0.447233\n",
      "Epoch 800, Loss: 0.444839\n",
      "Epoch 900, Loss: 0.443141\n"
     ]
    }
   ],
   "source": [
    "# Initialize ARZ model\n",
    "arz_model = TrafficFlowForARZ_PINN(hidden_layers=8, neurons_per_layer=20)\n",
    "optimizer = torch.optim.Adam(arz_model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = arz_model(x, t)\n",
    "    rho_pred, u_pred = pred[:, 0:1], pred[:, 1:2]\n",
    "\n",
    "    # Data loss for density and velocity with real values\n",
    "    data_loss_rho = torch.mean((rho_pred - rho)**2)\n",
    "    data_loss_u = torch.mean((u_pred - u)**2)\n",
    "\n",
    "    # Physics loss\n",
    "    physics_loss = physics_loss_calculator(x, t, arz_model, beta1=1.0, beta2=1.0,\n",
    "                                         gamma1=1.0, gamma2=1.0, tau=0.02)\n",
    "\n",
    "    total_loss = data_loss_rho + data_loss_u + physics_loss\n",
    "\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d23e4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d5cab1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results:\n",
      "R² score for density (ρ): 0.0028\n",
      "R² score for velocity (u): 0.0158\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for sklearn - use .detach() to remove from computational graph\n",
    "X_data = np.hstack((x.detach().numpy(), t.detach().numpy()))\n",
    "rho_data = rho.detach().numpy().ravel()\n",
    "u_data = u.detach().numpy().ravel()\n",
    "\n",
    "# Train separate models for density and velocity\n",
    "lr_rho = LinearRegression().fit(X_data, rho_data)\n",
    "lr_u = LinearRegression().fit(X_data, u_data)\n",
    "\n",
    "print(\"Linear Regression Results:\")\n",
    "print(f\"R² score for density (ρ): {lr_rho.score(X_data, rho_data):.4f}\")\n",
    "print(f\"R² score for velocity (u): {lr_u.score(X_data, u_data):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935d1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vanilla ANN on ARZ model\n",
    "from Scripts.vanilla import VanillaMLP\n",
    "vanilla_model = VanillaMLP(hidden_layers=8, neurons_per_layer=20, output_dim=2)\n",
    "vanilla_optimizer = torch.optim.Adam(vanilla_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9427ad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Vanilla MLP...\n",
      "Vanilla MLP Epoch 0, Loss: 1.151428\n",
      "Vanilla MLP Epoch 100, Loss: 0.173437\n",
      "Vanilla MLP Epoch 200, Loss: 0.143880\n",
      "Vanilla MLP Epoch 300, Loss: 0.142410\n",
      "Vanilla MLP Epoch 400, Loss: 0.141470\n",
      "Vanilla MLP Epoch 500, Loss: 0.140240\n",
      "Vanilla MLP Epoch 600, Loss: 0.137996\n",
      "Vanilla MLP Epoch 700, Loss: 0.135057\n",
      "Vanilla MLP Epoch 800, Loss: 0.132480\n",
      "Vanilla MLP Epoch 900, Loss: 0.129982\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training Vanilla MLP...\")\n",
    "for epoch in range(1000):\n",
    "    vanilla_optimizer.zero_grad()\n",
    "    pred = vanilla_model(x, t)\n",
    "    rho_pred, u_pred = pred[:, 0:1], pred[:, 1:2]\n",
    "    \n",
    "    # Only data loss - no physics constraints\n",
    "    loss_rho = torch.mean((rho_pred - rho)**2)\n",
    "    loss_u = torch.mean((u_pred - u)**2)\n",
    "    total_loss = loss_rho + loss_u\n",
    "    \n",
    "    total_loss.backward()\n",
    "    vanilla_optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Vanilla MLP Epoch {epoch}, Loss: {total_loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67999f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM for ARZ model\n",
    "\n",
    "from Scripts.lstm import LSTMNet\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95d359da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sequential data for LSTM\n",
    "def prepare_lstm_data(x, t, rho, u, seq_length=10):\n",
    "    data = torch.cat([x, t, rho, u], dim=1)\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i+seq_length, :2]  # x,t as input sequence\n",
    "        target = data[i+seq_length, 2:4]  # rho, u as target\n",
    "        sequences.append(seq.unsqueeze(0))\n",
    "        targets.append(target.unsqueeze(0))\n",
    "    \n",
    "    if len(sequences) == 0:\n",
    "        raise ValueError(\"Not enough data for sequences\")\n",
    "    \n",
    "    sequences = torch.cat(sequences, dim=0)\n",
    "    targets = torch.cat(targets, dim=0)\n",
    "    return sequences, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95368a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing LSTM data...\n",
      "Training LSTM...\n",
      "LSTM Epoch 0, Loss: 0.208867\n",
      "LSTM Epoch 100, Loss: 0.089203\n",
      "LSTM Epoch 200, Loss: 0.068139\n",
      "LSTM Epoch 300, Loss: 0.056532\n",
      "LSTM Epoch 400, Loss: 0.054961\n",
      "LSTM Epoch 500, Loss: 0.050927\n",
      "LSTM Epoch 600, Loss: 0.043343\n",
      "LSTM Epoch 700, Loss: 0.041090\n",
      "LSTM Epoch 800, Loss: 0.037508\n",
      "LSTM Epoch 900, Loss: 0.033571\n"
     ]
    }
   ],
   "source": [
    "lstm_model = LSTMNet(input_size=2, hidden_size=50, num_layers=2, output_size=2)\n",
    "lstm_optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(\"Preparing LSTM data...\")\n",
    "sequences, targets = prepare_lstm_data(x, t, rho, u, seq_length=10)\n",
    "\n",
    "print(\"Training LSTM...\")\n",
    "for epoch in range(1000):\n",
    "    lstm_optimizer.zero_grad()\n",
    "    outputs = lstm_model(sequences)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    lstm_optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"LSTM Epoch {epoch}, Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efe2265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(x_test, t_test, rho_test, u_test, models_dict, seq_length=10):\n",
    "    \"\"\"\n",
    "    Evaluate all models and return metrics\n",
    "    models_dict: {'model_name': model_object}\n",
    "    \"\"\"\n",
    "    import torch.nn.functional as F\n",
    "    \n",
    "    results = {}\n",
    "    X_test = np.hstack((x_test.detach().numpy(), t_test.detach().numpy()))\n",
    "    \n",
    "    for name, model in models_dict.items():\n",
    "        if name == 'Linear Regression':\n",
    "            rho_pred = torch.tensor(model[0].predict(X_test), dtype=torch.float32).reshape(-1,1)\n",
    "            u_pred = torch.tensor(model[1].predict(X_test), dtype=torch.float32).reshape(-1,1)\n",
    "            \n",
    "        elif name == 'LSTM':\n",
    "            # Prepare sequential test data for LSTM\n",
    "            test_data = torch.cat([x_test, t_test, rho_test, u_test], dim=1)\n",
    "            test_sequences = []\n",
    "            test_targets = []\n",
    "            \n",
    "            for i in range(len(test_data) - seq_length):\n",
    "                seq = test_data[i:i+seq_length, :2]  # x,t\n",
    "                target = test_data[i+seq_length, 2:4]  # rho, u\n",
    "                test_sequences.append(seq.unsqueeze(0))\n",
    "                test_targets.append(target.unsqueeze(0))\n",
    "            \n",
    "            if len(test_sequences) == 0:\n",
    "                print(f\"Warning: Not enough test data for LSTM sequences\")\n",
    "                continue\n",
    "                \n",
    "            test_sequences = torch.cat(test_sequences, dim=0)\n",
    "            test_targets = torch.cat(test_targets, dim=0)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                lstm_pred = model(test_sequences)\n",
    "                rho_pred = lstm_pred[:, 0:1]\n",
    "                u_pred = lstm_pred[:, 1:2]\n",
    "                \n",
    "            # Use corresponding targets for evaluation\n",
    "            rho_test_lstm = test_targets[:, 0:1]\n",
    "            u_test_lstm = test_targets[:, 1:2]\n",
    "            \n",
    "            # Calculate metrics for LSTM\n",
    "            mse_rho = F.mse_loss(rho_pred, rho_test_lstm).item()\n",
    "            mse_u = F.mse_loss(u_pred, u_test_lstm).item()\n",
    "            mae_rho = F.l1_loss(rho_pred, rho_test_lstm).item()\n",
    "            mae_u = F.l1_loss(u_pred, u_test_lstm).item()\n",
    "            \n",
    "            results[name] = {\n",
    "                'MSE_rho': mse_rho,\n",
    "                'MSE_u': mse_u, \n",
    "                'MAE_rho': mae_rho,\n",
    "                'MAE_u': mae_u,\n",
    "                'Total_MSE': mse_rho + mse_u\n",
    "            }\n",
    "            continue  # Skip the general evaluation below\n",
    "            \n",
    "        else:  # Neural networks (PINN, Vanilla MLP)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x_test, t_test)\n",
    "                rho_pred, u_pred = pred[:, 0:1], pred[:, 1:2]\n",
    "        \n",
    "        # Calculate metrics for non-LSTM models\n",
    "        if name != 'LSTM':\n",
    "            mse_rho = F.mse_loss(rho_pred, rho_test).item()\n",
    "            mse_u = F.mse_loss(u_pred, u_test).item()\n",
    "            mae_rho = F.l1_loss(rho_pred, rho_test).item()\n",
    "            mae_u = F.l1_loss(u_pred, u_test).item()\n",
    "            \n",
    "            results[name] = {\n",
    "                'MSE_rho': mse_rho,\n",
    "                'MSE_u': mse_u, \n",
    "                'MAE_rho': mae_rho,\n",
    "                'MAE_u': mae_u,\n",
    "                'Total_MSE': mse_rho + mse_u\n",
    "            }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d0b0e19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODEL COMPARISON RESULTS\n",
      "============================================================\n",
      "\n",
      "PINN_ARZ:\n",
      "----------------------------------------\n",
      "  MSE_rho: 0.139779\n",
      "  MSE_u: 0.298854\n",
      "  MAE_rho: 0.294851\n",
      "  MAE_u: 0.428265\n",
      "  Total_MSE: 0.438632\n",
      "\n",
      "Vanilla_MLP:\n",
      "----------------------------------------\n",
      "  MSE_rho: 0.057946\n",
      "  MSE_u: 0.096258\n",
      "  MAE_rho: 0.193039\n",
      "  MAE_u: 0.276417\n",
      "  Total_MSE: 0.154204\n",
      "\n",
      "LSTM:\n",
      "----------------------------------------\n",
      "  MSE_rho: 0.031319\n",
      "  MSE_u: 0.033264\n",
      "  MAE_rho: 0.141113\n",
      "  MAE_u: 0.142298\n",
      "  Total_MSE: 0.064583\n",
      "\n",
      "Linear Regression:\n",
      "----------------------------------------\n",
      "  MSE_rho: 0.092448\n",
      "  MSE_u: 0.116436\n",
      "  MAE_rho: 0.234909\n",
      "  MAE_u: 0.307580\n",
      "  Total_MSE: 0.208884\n"
     ]
    }
   ],
   "source": [
    "# Updated usage after training all models:\n",
    "models_to_compare = {\n",
    "    'PINN_ARZ': arz_model,  # Your trained ARZ model\n",
    "    'Vanilla_MLP': vanilla_model,\n",
    "    'LSTM': lstm_model,  # Add your trained LSTM model\n",
    "    'Linear Regression': (lr_rho, lr_u)\n",
    "}\n",
    "\n",
    "# Split your data for testing (use last 20% as test)\n",
    "test_size = int(0.2 * len(x))\n",
    "x_test, t_test = x[-test_size:], t[-test_size:]\n",
    "rho_test, u_test = rho[-test_size:], u[-test_size:]\n",
    "\n",
    "comparison_results = evaluate_models(x_test, t_test, rho_test, u_test, models_to_compare, seq_length=10)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for model_name, metrics in comparison_results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aad22b8",
   "metadata": {},
   "source": [
    "**We can clearly see that PINNs have performed relatively poorer wrt the established models, however, these numbers are evalueated on training data solely. Now, we will extract a test dataset and will validate the models based on the unseen data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac7e8214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4469348",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://data.transportation.gov/resource/8ect-6jqj.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71532cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_ngsim_api(location=None, direction=None, lane=None,\n",
    "                    t_start_ms=None, t_end_ms=None,\n",
    "                    limit=50000, max_pages=20, app_token=None):\n",
    "    headers = {}\n",
    "    if app_token:\n",
    "        headers[\"X-App-Token\"] = app_token\n",
    "\n",
    "    where_clauses = []\n",
    "    if location:  where_clauses.append(f\"location='{location}'\")\n",
    "    if direction is not None: where_clauses.append(f\"direction='{direction}'\")\n",
    "    if lane is not None:      where_clauses.append(f\"lane_id='{lane}'\")\n",
    "    if t_start_ms is not None: where_clauses.append(f\"global_time >= '{t_start_ms}'\")\n",
    "    if t_end_ms is not None:   where_clauses.append(f\"global_time <= '{t_end_ms}'\")\n",
    "    where = \" AND \".join(where_clauses) if where_clauses else None\n",
    "\n",
    "    params = {\n",
    "        \"$select\": \"vehicle_id,frame_id,global_time,global_x,global_y,local_x,local_y,v_vel,lane_id,direction,location\",\n",
    "        \"$order\": \"global_time ASC\",\n",
    "        \"$limit\": limit\n",
    "    }\n",
    "    if where:\n",
    "        params[\"$where\"] = where\n",
    "\n",
    "    frames = []\n",
    "    offset = 0\n",
    "    for _ in range(max_pages):\n",
    "        params[\"$offset\"] = offset\n",
    "        r = requests.get(BASE_URL, params=params, headers=headers, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        chunk = r.json()\n",
    "        if not chunk:\n",
    "            break\n",
    "        frames.append(pd.DataFrame(chunk))\n",
    "        offset += limit\n",
    "    if not frames:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    # Types & units\n",
    "    to_float = [\"global_time\",\"global_x\",\"global_y\",\"local_x\",\"local_y\",\"v_vel\"]\n",
    "    to_int   = [\"frame_id\",\"lane_id\",\"direction\"]\n",
    "    for c in to_float:\n",
    "        if c in df.columns: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    for c in to_int:\n",
    "        if c in df.columns: df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # Time to seconds\n",
    "    if \"global_time\" in df and df[\"global_time\"].max() > 1e6:\n",
    "        df[\"t\"] = df[\"global_time\"] / 1000.0\n",
    "    else:\n",
    "        # Fallback from frame_id (10Hz)\n",
    "        df[\"t\"] = df[\"frame_id\"] / 10.0\n",
    "\n",
    "    # Rename for consistency; use Global_X as longitudinal x\n",
    "    df = df.rename(columns={\n",
    "        \"global_x\":\"x\", \"v_vel\":\"speed\", \"lane_id\":\"lane\",\n",
    "        \"direction\":\"dir\", \"location\":\"loc\"\n",
    "    })\n",
    "\n",
    "    # mph -> m/s if needed (this dataset looks like mph)\n",
    "    if df[\"speed\"].dropna().median() > 70:\n",
    "        df[\"speed\"] = df[\"speed\"] * 0.44704\n",
    "\n",
    "    return df[[\"vehicle_id\",\"t\",\"x\",\"speed\",\"lane\",\"dir\",\"loc\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bcaa28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  vehicle_id          t            x  speed  lane  dir        loc\n",
      "0       1473  1163950.0  2230837.798  24.71     1    2  peachtree\n",
      "1       1476  1163950.0  2230825.803  22.89     1    2  peachtree\n",
      "2       1372  1163950.0  2230843.930  35.96     1    2  peachtree\n",
      "3       1543  1163950.0  2230831.653  26.33     1    2  peachtree\n",
      "4       1445  1163950.0  2230617.723  47.13     1    2  peachtree (4935, 7)\n"
     ]
    }
   ],
   "source": [
    "# Choose a 5-minute window again\n",
    "t0_ms = 1163050000 + 15*60*1000\n",
    "t1_ms = 1163050000 + 20*60*1000\n",
    "\n",
    "df = fetch_ngsim_api(location=\"peachtree\", direction=2, lane=1,\n",
    "                     t_start_ms=t0_ms, t_end_ms=t1_ms, limit=50000)\n",
    "print(df.head(), df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cdb553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_to_grid_df(df, minutes=10, dx=10.0, dt=1.0):\n",
    "    # Ensure we have at least some rows\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No data after API filtering\")\n",
    "\n",
    "    # Time slice to exactly minutes duration from min t\n",
    "    t0 = df[\"t\"].min()\n",
    "    t1 = t0 + 60*minutes\n",
    "    df = df[(df[\"t\"]>=t0) & (df[\"t\"]<=t1)].copy()\n",
    "\n",
    "    # Spatial slice (trim outliers)\n",
    "    x_min = df[\"x\"].quantile(0.01)\n",
    "    x_max = df[\"x\"].quantile(0.99)\n",
    "    df = df[df[\"x\"].between(x_min, x_max)]\n",
    "\n",
    "    # Define bins and centers\n",
    "    x_bins = np.arange(x_min, x_max+dx, dx)\n",
    "    t_bins = np.arange(t0, t1+dt, dt)\n",
    "    x_c = (x_bins[:-1] + x_bins[1:]) / 2\n",
    "    t_c = (t_bins[:-1] + t_bins[1:]) / 2\n",
    "\n",
    "    Ix, Jt = len(x_c), len(t_c)\n",
    "    rho = np.full((Ix, Jt), np.nan)\n",
    "    u   = np.full((Ix, Jt), np.nan)\n",
    "\n",
    "    for j,(ta,tb) in enumerate(zip(t_bins[:-1], t_bins[1:])):\n",
    "        df_t = df[(df[\"t\"]>=ta)&(df[\"t\"]<tb)]\n",
    "        if df_t.empty: continue\n",
    "        idx = np.digitize(df_t[\"x\"].values, x_bins) - 1\n",
    "        m = (idx>=0) & (idx<Ix)\n",
    "        idx = idx[m]; spd = df_t[\"speed\"].values[m]\n",
    "        counts = np.bincount(idx, minlength=Ix)\n",
    "        sums   = np.bincount(idx, weights=spd, minlength=Ix)\n",
    "        with np.errstate(invalid=\"ignore\"):\n",
    "            u[:,j]   = np.where(counts>0, sums/counts, np.nan)\n",
    "            rho[:,j] = np.where(counts>0, counts/dx, np.nan)  # veh/m\n",
    "\n",
    "    mask = ~np.isnan(rho)\n",
    "    rho_f = np.where(mask, rho, 0.0)\n",
    "    u_f   = np.where(mask, u,   0.0)\n",
    "\n",
    "    rho_max = np.nanpercentile(rho, 99)\n",
    "    v_free  = np.nanpercentile(u, 95)\n",
    "    rho_nd  = np.clip(rho_f/rho_max, 0, 1)\n",
    "    u_nd    = np.clip(u_f/v_free,    0, 1)\n",
    "\n",
    "    x_nd = (x_c - x_c.min())/(x_c.max()-x_c.min())\n",
    "    t_nd = (t_c - t_c.min())/(t_c.max()-t_c.min())\n",
    "    Xg, Tg = np.meshgrid(x_nd, t_nd, indexing=\"ij\")\n",
    "\n",
    "    tensors = {\n",
    "        \"x\": torch.tensor(Xg.reshape(-1,1), dtype=torch.float32),\n",
    "        \"t\": torch.tensor(Tg.reshape(-1,1), dtype=torch.float32),\n",
    "        \"rho\": torch.tensor(rho_nd.reshape(-1,1), dtype=torch.float32),\n",
    "        \"u\": torch.tensor(u_nd.reshape(-1,1), dtype=torch.float32),\n",
    "        \"mask\": torch.tensor(mask.reshape(-1,1), dtype=torch.float32),\n",
    "        \"rho_max\": float(rho_max),\n",
    "        \"v_free\": float(v_free),\n",
    "        \"x_centers\": x_c, \"t_centers\": t_c\n",
    "    }\n",
    "    return tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors2 = aggregate_to_grid_df(df, minutes=10, dx=10.0, dt=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbbf0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = tensors2[\"x\"].numpy().ravel()\n",
    "t_val = tensors2[\"t\"].numpy().ravel()\n",
    "rho_val = tensors2[\"rho\"].numpy().ravel()\n",
    "u_val = tensors2[\"u\"].numpy().ravel()\n",
    "mask_val = tensors2[\"mask\"].numpy().ravel().astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19d64caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = torch.tensor(x_val, dtype=torch.float32).reshape(-1,1)\n",
    "t_val = torch.tensor(t_val, dtype=torch.float32).reshape(-1,1)\n",
    "rho_val = torch.tensor(rho_val, dtype=torch.float32).reshape(-1,1)\n",
    "u_val = torch.tensor(u_val, dtype=torch.float32).reshape(-1,1)\n",
    "mask_val = torch.tensor(mask_val, dtype=torch.bool).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c262047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx_2 = mask_val.squeeze(1)\n",
    "x_val, t_val, rho_val, u_val = x_val[valid_idx_2], t_val[valid_idx_2], rho_val[valid_idx_2], u_val[valid_idx_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1e66bcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALIDATION MODEL COMPARISON RESULTS\n",
      "============================================================\n",
      "\n",
      "PINN_ARZ:\n",
      "----------------------------------------\n",
      "  MSE_rho: 0.080758\n",
      "  MSE_u: 0.477265\n",
      "  MAE_rho: 0.191039\n",
      "  MAE_u: 0.575047\n",
      "  Total_MSE: 0.558023\n",
      "\n",
      "Vanilla_MLP:\n",
      "----------------------------------------\n",
      "  MSE_rho: 0.063808\n",
      "  MSE_u: 0.151488\n",
      "  MAE_rho: 0.173839\n",
      "  MAE_u: 0.335677\n",
      "  Total_MSE: 0.215296\n",
      "\n",
      "LSTM:\n",
      "----------------------------------------\n",
      "  MSE_rho: 0.075076\n",
      "  MSE_u: 0.120174\n",
      "  MAE_rho: 0.178074\n",
      "  MAE_u: 0.263052\n",
      "  Total_MSE: 0.195250\n",
      "\n",
      "Linear Regression:\n",
      "----------------------------------------\n",
      "  MSE_rho: 0.064216\n",
      "  MSE_u: 0.164253\n",
      "  MAE_rho: 0.193679\n",
      "  MAE_u: 0.378048\n",
      "  Total_MSE: 0.228469\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all models on validation data\n",
    "models_to_compare_val = {\n",
    "    'PINN_ARZ': arz_model,  # Your trained ARZ model\n",
    "    'Vanilla_MLP': vanilla_model,\n",
    "    'LSTM': lstm_model,\n",
    "    'Linear Regression': (lr_rho, lr_u)\n",
    "}\n",
    "\n",
    "validation_results = evaluate_models(x_val, t_val, rho_val, u_val, models_to_compare_val, seq_length=10)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VALIDATION MODEL COMPARISON RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for model_name, metrics in validation_results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c14a7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Physics Residual (Mean Squared PDE violation) on Validation Data:\n",
      "PINN_ARZ: 0.000076\n"
     ]
    }
   ],
   "source": [
    "# Only calculate physics residual for PINN models\n",
    "x_val.requires_grad_(True)\n",
    "t_val.requires_grad_(True)\n",
    "\n",
    "# Calculate physics residual only for PINN\n",
    "pinn_phys_residual = torch.mean(physics_loss_calculator(x_val, t_val, arz_model)**2).item()\n",
    "\n",
    "print(f\"\\nPhysics Residual (Mean Squared PDE violation) on Validation Data:\")\n",
    "print(f\"PINN_ARZ: {pinn_phys_residual:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072fdbc5",
   "metadata": {},
   "source": [
    "**As we can see, the physics loss incurred is a very small number, i.e the model predicts the physics behind the phenomena appropriately, while this largely points towards the other non-physics model being physically somehwat inaccurate, most likely picking up noise while training. This thereby proves that the PINNs have performed accurately while having slightly higher losses.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
